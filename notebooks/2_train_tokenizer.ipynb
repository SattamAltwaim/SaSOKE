{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattamAltwaim/SaSOKE/blob/main/notebooks/2_train_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR5jYtLpM8-v"
      },
      "source": [
        "# SOKE Stage 1: Train Decoupled Tokenizer (DETO)\n",
        "Trains VQ-VAE models to discretize continuous sign language poses into tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_YwIogFM8-w"
      },
      "outputs": [],
      "source": [
        "# Clone repo if not already present\n",
        "import os\n",
        "if not os.path.exists('/content/SaSOKE'):\n",
        "    !git clone https://github.com/SattamAltwaim/SaSOKE.git\n",
        "%cd /content/SaSOKE\n",
        "\n",
        "# Mount Drive for data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_data = '/content/drive/MyDrive/GraduationProject/CodeFiles/SaSOKE'\n",
        "print(\"Code repo:\", os.getcwd())\n",
        "print(\"Data location:\", drive_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdW7VJr0M8-x"
      },
      "source": [
        "## Configuration Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-MQkNwhM8-x"
      },
      "outputs": [],
      "source": [
        "# Update config paths for Colab/CUDA environment\n",
        "import yaml\n",
        "\n",
        "with open('configs/deto.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Update for CUDA\n",
        "config['ACCELERATOR'] = 'gpu'\n",
        "config['DEVICE'] = [0]\n",
        "\n",
        "# Point to Drive for data/models\n",
        "config['DATASET']['H2S']['ROOT'] = f'{drive_data}/data/How2Sign'\n",
        "config['DATASET']['H2S']['MEAN_PATH'] = f'{drive_data}/smpl-x/mean.pt'\n",
        "config['DATASET']['H2S']['STD_PATH'] = f'{drive_data}/smpl-x/std.pt'\n",
        "\n",
        "# Reduce workers for Colab\n",
        "config['TRAIN']['NUM_WORKERS'] = 2\n",
        "\n",
        "# Save updated config\n",
        "with open('configs/deto_colab.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(\"Config updated - code from GitHub, data from Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2OihcA8M8-x"
      },
      "source": [
        "## Train Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YgXVZp4M8-x"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "!python -m train --cfg configs/deto_colab.yaml --nodebug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-SefOh7M8-y"
      },
      "source": [
        "## Monitor Training\n",
        "Check tensorboard logs in `experiments/mgpt/DETO/` or use W&B if configured.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El93o_V1M8-y"
      },
      "outputs": [],
      "source": [
        "# Load tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir experiments/mgpt/DETO/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHtchbbzM8-y"
      },
      "source": [
        "## Copy Checkpoint\n",
        "After training, copy the checkpoint to the expected location for SOKE training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXShbsGqM8-y"
      },
      "outputs": [],
      "source": [
        "# Copy checkpoint to Drive\n",
        "!mkdir -p {drive_data}/checkpoints/vae\n",
        "!cp experiments/mgpt/DETO/checkpoints/last.ckpt {drive_data}/checkpoints/vae/tokenizer.ckpt\n",
        "print(f\"Tokenizer saved to {drive_data}/checkpoints/vae/tokenizer.ckpt\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}