{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattamAltwaim/SaSOKE/blob/main/notebooks/5_text_to_sign_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-Sign Language Inference\n",
        "Generate sign language from custom text input using SOKE model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repo if not present\n",
        "import os\n",
        "if not os.path.exists('/content/SaSOKE'):\n",
        "    !git clone https://github.com/SattamAltwaim/SaSOKE.git\n",
        "%cd /content/SaSOKE\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_data = '/content/drive/MyDrive/GraduationProject/CodeFiles/SaSOKE'\n",
        "print(\"\u2713 Code:\", os.getcwd())\n",
        "print(\"\u2713 Data:\", drive_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (if needed)\n",
        "%pip install -q pytorch_lightning torchmetrics omegaconf shortuuid transformers einops rich matplotlib sentencepiece\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Verify GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No GPU detected! Go to Runtime \u2192 Change runtime type \u2192 GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Enter Your Custom Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your text here - you can modify this!\n",
        "custom_texts = [\n",
        "    \"Hello, how are you today?\",\n",
        "    \"Thank you for your help.\",\n",
        "    \"I am learning sign language.\"\n",
        "]\n",
        "\n",
        "# Or enter a single text\n",
        "# custom_texts = [\"Your custom text here\"]\n",
        "\n",
        "print(\"Input texts:\")\n",
        "for i, text in enumerate(custom_texts, 1):\n",
        "    print(f\"{i}. {text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Inference on Your Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from mGPT.config import parse_args\n",
        "from mGPT.models.build_model import build_model\n",
        "from mGPT.data.build_data import build_data\n",
        "from mGPT.utils.load_checkpoint import load_pretrained_vae, load_pretrained\n",
        "from mGPT.utils.logger import create_logger\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# Configure paths\n",
        "with open('configs/soke.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "config['ACCELERATOR'] = 'gpu'\n",
        "config['DEVICE'] = [0]\n",
        "config['DATASET']['H2S']['ROOT'] = f'{drive_data}/data/How2Sign'\n",
        "config['DATASET']['H2S']['MEAN_PATH'] = f'{drive_data}/smpl-x/mean.pt'\n",
        "config['DATASET']['H2S']['STD_PATH'] = f'{drive_data}/smpl-x/std.pt'\n",
        "config['TRAIN']['PRETRAINED_VAE'] = f'{drive_data}/checkpoints/vae/tokenizer.ckpt'\n",
        "\n",
        "with open('configs/text_inference.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "# Update assets\n",
        "with open('configs/assets.yaml', 'r') as f:\n",
        "    assets = yaml.safe_load(f)\n",
        "assets['METRIC']['TM2T']['t2m_path'] = f'{drive_data}/deps/t2m/t2m/'\n",
        "with open('configs/assets_inference.yaml', 'w') as f:\n",
        "    yaml.dump(assets, f)\n",
        "\n",
        "# Parse config\n",
        "import sys\n",
        "sys.argv = ['', '--cfg', 'configs/text_inference.yaml', '--cfg_assets', 'configs/assets_inference.yaml']\n",
        "cfg = parse_args(phase=\"test\")\n",
        "cfg.FOLDER = cfg.TEST.FOLDER\n",
        "\n",
        "# Seed\n",
        "pl.seed_everything(cfg.SEED_VALUE)\n",
        "\n",
        "# Build data and model\n",
        "print(\"Loading model...\")\n",
        "datamodule = build_data(cfg)\n",
        "model = build_model(cfg, datamodule)\n",
        "\n",
        "# Load checkpoints\n",
        "logger = create_logger(cfg, phase=\"test\")\n",
        "if cfg.TRAIN.PRETRAINED_VAE:\n",
        "    load_pretrained_vae(cfg, model, logger)\n",
        "\n",
        "# Check for trained checkpoint\n",
        "ckpt_path = f'{drive_data}/experiments/mgpt/SOKE/checkpoints/last.ckpt'\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(f\"Loading trained checkpoint from {ckpt_path}\")\n",
        "    cfg.TEST.CHECKPOINTS = ckpt_path\n",
        "    load_pretrained(cfg, model, logger, phase=\"test\")\n",
        "else:\n",
        "    print(\"Using pretrained mBART (no fine-tuned checkpoint found)\")\n",
        "\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "print(\"\u2713 Model ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to convert features to SMPL-X parameters",
        "def feats_to_smplx(features, mean, std):",
        "    \"\"\"Convert 133-dim compressed features to SMPL-X parameters.\"\"\"",
        "    # Denormalize features",
        "    features = features * std + mean",
        "    ",
        "    # Add zero root pose (36 dims) to get 169 dims total",
        "    T = features.shape[0]",
        "    zero_pose = torch.zeros(T, 36).to(features)",
        "    features_full = torch.cat([zero_pose, features], dim=-1)  # (T, 169)",
        "    ",
        "    # Extract SMPL-X parameters",
        "    smplx_params = {",
        "        'root_pose': features_full[:, 0:3].cpu().numpy(),",
        "        'body_pose': features_full[:, 3:66].cpu().numpy(),",
        "        'lhand_pose': features_full[:, 66:111].cpu().numpy(),",
        "        'rhand_pose': features_full[:, 111:156].cpu().numpy(),",
        "        'jaw_pose': features_full[:, 156:159].cpu().numpy(),",
        "        'expression': features_full[:, 159:169].cpu().numpy(),",
        "    }",
        "    return smplx_params",
        "",
        "# Generate sign language poses",
        "output_dir = 'text_sign_results'",
        "os.makedirs(output_dir, exist_ok=True)",
        "",
        "print(f\"\\nGenerating sign language for {len(custom_texts)} text(s)...\\n\")",
        "",
        "# Get mean and std for denormalization",
        "mean = datamodule.hparams.mean.cuda()",
        "std = datamodule.hparams.std.cuda()",
        "",
        "with torch.no_grad():",
        "    for idx, text in enumerate(custom_texts):",
        "        print(f\"[{idx+1}/{len(custom_texts)}] Processing: '{text}'\")",
        "        ",
        "        # Prepare input",
        "        batch = {",
        "            'text': [text]",
        "        }",
        "        ",
        "        try:",
        "            # Generate FULL SEQUENCE",
        "            output = model.t2m_eval(batch)",
        "            ",
        "            # Extract features",
        "            feats = output['feats'][0] if 'feats' in output else None",
        "            ",
        "            if feats is None:",
        "                print(f\"  \u2717 No features generated\")",
        "                continue",
        "            ",
        "            # Convert to SMPL-X parameters (full sequence)",
        "            smplx_params = feats_to_smplx(feats, mean, std)",
        "            ",
        "            # Save result (NO TOKENS, only SMPL-X params)",
        "            filename = f\"text_{idx+1}.pkl\"",
        "            filepath = os.path.join(output_dir, filename)",
        "            ",
        "            result = {",
        "                'text': text,",
        "                'smplx_params': smplx_params,  # Full sequence of SMPL-X poses",
        "                'num_frames': smplx_params['body_pose'].shape[0]",
        "            }",
        "            ",
        "            with open(filepath, 'wb') as f:",
        "                pickle.dump(result, f)",
        "            ",
        "            print(f\"  \u2713 Saved: {filepath}\")",
        "            print(f\"    - Frames: {result['num_frames']}\")",
        "            print(f\"    - SMPL-X parameters saved (no tokens)\")",
        "            ",
        "        except Exception as e:",
        "            print(f\"  \u2717 Error: {e}\")",
        "            import traceback",
        "            traceback.print_exc()",
        "            continue",
        "",
        "print(f\"\\n\u2713 Complete! Predictions saved in '{output_dir}'\")",
        "print(f\"\\nTo play the animations, download results and use:\")",
        "print(f\"  python3 generate_animation_html.py text_sign_results/text_1.pkl\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. View Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List generated files",
        "print(\"Generated predictions:\")",
        "!ls -lh {output_dir}",
        "",
        "# Load and display results",
        "pkl_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.pkl')])",
        "",
        "for pkl_file in pkl_files:",
        "    filepath = os.path.join(output_dir, pkl_file)",
        "    ",
        "    with open(filepath, 'rb') as f:",
        "        result = pickle.load(f)",
        "    ",
        "    print(f\"\\n{pkl_file}:\")",
        "    print(f\"  Text: {result['text']}\")",
        "    print(f\"  Frames: {result['num_frames']}\")",
        "    ",
        "    # Display SMPL-X parameters info",
        "    if result.get('smplx_params') is not None:",
        "        smplx = result['smplx_params']",
        "        print(f\"  SMPL-X Parameters:\")",
        "        print(f\"    - root_pose: {smplx['root_pose'].shape} (global orientation)\")",
        "        print(f\"    - body_pose: {smplx['body_pose'].shape} (21 body joints \u00d7 3)\")",
        "        print(f\"    - lhand_pose: {smplx['lhand_pose'].shape} (15 left hand joints \u00d7 3)\")",
        "        print(f\"    - rhand_pose: {smplx['rhand_pose'].shape} (15 right hand joints \u00d7 3)\")",
        "        print(f\"    - jaw_pose: {smplx['jaw_pose'].shape} (jaw rotation)\")",
        "        print(f\"    - expression: {smplx['expression'].shape} (facial expression)\")",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zip results for easy download\n",
        "!zip -r text_sign_results.zip {output_dir}/\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('text_sign_results.zip')\n",
        "\n",
        "print(\"\u2713 Results packaged and ready to download\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- **GPU Required**: Make sure you're using a GPU runtime (Runtime \u2192 Change runtime type \u2192 GPU \u2192 T4/V100/A100)\n",
        "- **First Time**: Run notebook 1 first to download all dependencies to your Google Drive\n",
        "- **Custom Text**: Simply modify the `custom_texts` list in cell 8 with your own text\n",
        "- **Output**: Each text generates a `.pkl` file containing predicted sign language poses (3D coordinates)\n",
        "- **Format**: Poses are in SMPL-X format and can be visualized using 3D animation tools\n",
        "\n",
        "### Troubleshooting\n",
        "- **OOM Error**: Reduce text length or batch size\n",
        "- **Missing files**: Make sure notebook 1 was run successfully to download models\n",
        "- **Slow generation**: Normal on T4 GPU, faster on V100/A100\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}