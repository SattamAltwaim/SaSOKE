{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattamAltwaim/SaSOKE/blob/main/notebooks/9_api_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmioyDv6faa7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattamAltwaim/SaSOKE/blob/main/notebooks/9_api_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBH2eudafaa_"
      },
      "source": [
        "# ü§ü SOKE API Server\n",
        "\n",
        "**Flask API that provides SMPL-X parameters and GLB frames for sign language generation**\n",
        "\n",
        "### Features\n",
        "- ‚úÖ REST API endpoint for text-to-sign generation\n",
        "- ‚úÖ Returns GLB frames (base64 encoded) ready for 3D display\n",
        "- ‚úÖ CORS enabled for frontend access\n",
        "- ‚úÖ Works with standalone Apple-style frontend\n",
        "\n",
        "### Requirements\n",
        "- **GPU Runtime**: `Runtime ‚Üí Change runtime type ‚Üí GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p489veNnfabA"
      },
      "source": [
        "## Step 1: Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gjt4BbcfabA"
      },
      "outputs": [],
      "source": [
        "# Clone repo and mount Drive\n",
        "import os\n",
        "if not os.path.exists('/content/SaSOKE'):\n",
        "    !git clone https://github.com/SattamAltwaim/SaSOKE.git\n",
        "%cd /content/SaSOKE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_data = '/content/drive/MyDrive/GraduationProject/CodeFiles/SaSOKE'\n",
        "print(\"‚úì Ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7sdtXDOfabC"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q pytorch_lightning torchmetrics omegaconf shortuuid transformers diffusers einops wandb rich matplotlib\n",
        "!pip install -q smplx h5py scikit-image spacy ftfy more-itertools natsort tensorboard sentencepiece\n",
        "!pip install -q flask flask-cors trimesh\n",
        "print(\"‚úì Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OZJmp0SfabD"
      },
      "source": [
        "## Step 2: Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_WUojN1fabD"
      },
      "outputs": [],
      "source": [
        "# Setup paths\n",
        "import sys\n",
        "import yaml\n",
        "from mGPT.config import parse_args\n",
        "\n",
        "deps_links = {\n",
        "    'deps/smpl_models': f'{drive_data}/deps/smpl_models',\n",
        "    'deps/mbart-h2s-csl-phoenix': f'{drive_data}/deps/mbart-h2s-csl-phoenix',\n",
        "}\n",
        "\n",
        "for expected_path, actual_path in deps_links.items():\n",
        "    if not os.path.exists(expected_path):\n",
        "        os.makedirs(os.path.dirname(expected_path), exist_ok=True)\n",
        "        os.symlink(actual_path, expected_path)\n",
        "\n",
        "with open('configs/soke.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "config['ACCELERATOR'] = 'gpu'\n",
        "config['DEVICE'] = [0]\n",
        "config['DATASET']['H2S']['ROOT'] = f'{drive_data}/data/How2Sign'\n",
        "config['DATASET']['H2S']['MEAN_PATH'] = f'{drive_data}/smpl-x/mean.pt'\n",
        "config['DATASET']['H2S']['STD_PATH'] = f'{drive_data}/smpl-x/std.pt'\n",
        "config['TRAIN']['PRETRAINED_VAE'] = f'{drive_data}/checkpoints/vae/tokenizer.ckpt'\n",
        "\n",
        "with open('configs/web_inference.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "with open('configs/assets.yaml', 'r') as f:\n",
        "    assets = yaml.safe_load(f)\n",
        "\n",
        "assets['RENDER']['SMPL_MODEL_PATH'] = 'deps/smpl_models/smpl'\n",
        "assets['RENDER']['MODEL_PATH'] = 'deps/smpl_models'\n",
        "assets['METRIC']['TM2T']['t2m_path'] = f'{drive_data}/deps/deps/t2m/t2m/'\n",
        "\n",
        "with open('configs/assets_web.yaml', 'w') as f:\n",
        "    yaml.dump(assets, f)\n",
        "\n",
        "sys.argv = ['', '--cfg', 'configs/web_inference.yaml', '--cfg_assets', 'configs/assets_web.yaml']\n",
        "cfg = parse_args(phase=\"test\")\n",
        "cfg.FOLDER = cfg.TEST.FOLDER\n",
        "print(\"‚úì Configuration ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs_hjT8bfabE"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from mGPT.models.build_model import build_model\n",
        "from mGPT.data.build_data import build_data\n",
        "from mGPT.utils.load_checkpoint import load_pretrained_vae, load_pretrained\n",
        "from mGPT.utils.logger import create_logger\n",
        "from mGPT.utils.human_models import smpl_x, get_coord\n",
        "\n",
        "pl.seed_everything(cfg.SEED_VALUE)\n",
        "cfg.DATASET.WORD_VERTILIZER_PATH = f'{drive_data}/deps/deps/t2m/glove/'\n",
        "\n",
        "datamodule = build_data(cfg)\n",
        "model = build_model(cfg, datamodule)\n",
        "\n",
        "logger = create_logger(cfg, phase=\"test\")\n",
        "if cfg.TRAIN.PRETRAINED_VAE:\n",
        "    load_pretrained_vae(cfg, model, logger)\n",
        "\n",
        "ckpt_path = f'{drive_data}/checkpoints/mGPT/last.ckpt'\n",
        "if os.path.exists(ckpt_path):\n",
        "    cfg.TEST.CHECKPOINTS = ckpt_path\n",
        "\n",
        "    # Get model state dict before loading\n",
        "    model_state_before = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    # Load checkpoint\n",
        "    load_pretrained(cfg, model, logger, phase=\"test\")\n",
        "\n",
        "    # Verify weights were loaded by checking if they changed\n",
        "    checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
        "    checkpoint_keys = set(checkpoint[\"state_dict\"].keys())\n",
        "    model_keys = set(model.state_dict().keys())\n",
        "\n",
        "    # Count matching keys\n",
        "    matching_keys = checkpoint_keys.intersection(model_keys)\n",
        "    loaded_count = 0\n",
        "    for key in matching_keys:\n",
        "        if key in model_state_before:\n",
        "            if not torch.equal(model.state_dict()[key], model_state_before[key]):\n",
        "                loaded_count += 1\n",
        "\n",
        "    print(f\"\\n‚úì Loaded model checkpoint from {ckpt_path}\")\n",
        "    print(f\"  - Checkpoint keys: {len(checkpoint_keys)}\")\n",
        "    print(f\"  - Model keys: {len(model_keys)}\")\n",
        "    print(f\"  - Matching keys: {len(matching_keys)}\")\n",
        "    print(f\"  - Weights updated: {loaded_count}\")\n",
        "    print(f\"  - Note: 'Weights not loaded' messages above are normal - they show which weights don't match the current model structure.\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Checkpoint not found at {ckpt_path}\")\n",
        "    print(f\"   Please ensure the checkpoint exists at this path.\")\n",
        "\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "mean = datamodule.hparams.mean.cuda()\n",
        "std = datamodule.hparams.std.cuda()\n",
        "\n",
        "print(\"\\n‚úÖ Model loaded and ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82B7MZGJrCGi"
      },
      "outputs": [],
      "source": [
        "# Patch model.forward to handle motion concatenation with proper padding\n",
        "import torch.nn.functional as F\n",
        "\n",
        "original_forward = model.forward\n",
        "\n",
        "def patched_forward(self, batch, task=\"t2m\"):\n",
        "    texts = batch[\"text\"]\n",
        "    lengths_ref = batch[\"length\"]\n",
        "    src = batch.get(\"src\", [\"how2sign\"] * len(texts))\n",
        "    name = batch.get(\"name\", [None] * len(texts))\n",
        "\n",
        "    gen_output = self.lm.generate_direct(texts, do_sample=True, src=src, name=name, max_length=400, num_beams=1)\n",
        "    outputs = gen_output['outputs_tokens']\n",
        "    outputs_hand = gen_output.get('outputs_tokens_hand', None)\n",
        "    outputs_rhand = gen_output.get('outputs_tokens_rhand', None)\n",
        "\n",
        "    feats_rst_lst = []\n",
        "    lengths = []\n",
        "    max_len = 0\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        # Get device from model parameters\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Ensure outputs[i] is a tensor and clamp\n",
        "        if isinstance(outputs[i], list):\n",
        "            outputs[i] = torch.tensor(outputs[i], dtype=torch.long, device=device)\n",
        "        else:\n",
        "            outputs[i] = outputs[i].to(device)\n",
        "        outputs[i] = torch.clamp(outputs[i], 0, self.vae.code_num - 1)\n",
        "\n",
        "        # Decode body motion\n",
        "        if len(outputs[i]) > 1:\n",
        "            motion = self.vae.decode(outputs[i])\n",
        "        else:\n",
        "            motion = torch.zeros(1, 1, self.vae.nfeats, device=device)\n",
        "\n",
        "        # Decode and pad hand motions to match body motion length\n",
        "        if outputs_hand is not None and hasattr(self, 'hand_vae') and self.hand_vae is not None:\n",
        "            if isinstance(outputs_hand[i], list):\n",
        "                outputs_hand[i] = torch.tensor(outputs_hand[i], dtype=torch.long, device=device)\n",
        "            else:\n",
        "                outputs_hand[i] = outputs_hand[i].to(device)\n",
        "            outputs_hand[i] = torch.clamp(outputs_hand[i], 0, self.hand_vae.code_num - 1)\n",
        "\n",
        "            if len(outputs_hand[i]) > 1:\n",
        "                motion_lhand = self.hand_vae.decode(outputs_hand[i])\n",
        "                # Ensure both have batch dimension\n",
        "                if motion_lhand.dim() == 2:\n",
        "                    motion_lhand = motion_lhand.unsqueeze(0)\n",
        "                if motion.dim() == 2:\n",
        "                    motion = motion.unsqueeze(0)\n",
        "                # Pad to match body motion temporal length\n",
        "                if motion_lhand.shape[1] != motion.shape[1]:\n",
        "                    if motion_lhand.shape[1] < motion.shape[1]:\n",
        "                        # Pad: (left, right, top, bottom) for 2D, or (left, right, front, back, top, bottom) for 3D\n",
        "                        # For (B, T, C): pad (0, 0, 0, 0, 0, T_diff)\n",
        "                        pad_amount = motion.shape[1] - motion_lhand.shape[1]\n",
        "                        motion_lhand = F.pad(motion_lhand, (0, 0, 0, pad_amount), mode='replicate')\n",
        "                    else:\n",
        "                        pad_amount = motion_lhand.shape[1] - motion.shape[1]\n",
        "                        motion = F.pad(motion, (0, 0, 0, pad_amount), mode='replicate')\n",
        "                motion = torch.cat([motion, motion_lhand], dim=-1)\n",
        "\n",
        "        if outputs_rhand is not None and hasattr(self, 'rhand_vae') and self.rhand_vae is not None:\n",
        "            if isinstance(outputs_rhand[i], list):\n",
        "                outputs_rhand[i] = torch.tensor(outputs_rhand[i], dtype=torch.long, device=device)\n",
        "            else:\n",
        "                outputs_rhand[i] = outputs_rhand[i].to(device)\n",
        "            outputs_rhand[i] = torch.clamp(outputs_rhand[i], 0, self.rhand_vae.code_num - 1)\n",
        "\n",
        "            if len(outputs_rhand[i]) > 1:\n",
        "                motion_rhand = self.rhand_vae.decode(outputs_rhand[i])\n",
        "                # Ensure both have batch dimension\n",
        "                if motion_rhand.dim() == 2:\n",
        "                    motion_rhand = motion_rhand.unsqueeze(0)\n",
        "                if motion.dim() == 2:\n",
        "                    motion = motion.unsqueeze(0)\n",
        "                # Pad to match current motion temporal length\n",
        "                if motion_rhand.shape[1] != motion.shape[1]:\n",
        "                    if motion_rhand.shape[1] < motion.shape[1]:\n",
        "                        pad_amount = motion.shape[1] - motion_rhand.shape[1]\n",
        "                        motion_rhand = F.pad(motion_rhand, (0, 0, 0, pad_amount), mode='replicate')\n",
        "                    else:\n",
        "                        pad_amount = motion_rhand.shape[1] - motion.shape[1]\n",
        "                        motion = F.pad(motion, (0, 0, 0, pad_amount), mode='replicate')\n",
        "                motion = torch.cat([motion, motion_rhand], dim=-1)\n",
        "\n",
        "        lengths.append(motion.shape[1])\n",
        "        if motion.shape[1] > max_len:\n",
        "            max_len = motion.shape[1]\n",
        "        feats_rst_lst.append(motion)\n",
        "\n",
        "    # Pad and concatenate all motions\n",
        "    device = next(self.parameters()).device\n",
        "    feats_rst = torch.zeros((len(feats_rst_lst), max_len, motion.shape[-1])).to(device)\n",
        "    for i in range(len(feats_rst_lst)):\n",
        "        feats_rst[i, :feats_rst_lst[i].shape[1], ...] = feats_rst_lst[i]\n",
        "\n",
        "    # Recover joints for evaluation\n",
        "    joints_rst = self.feats2joints(feats_rst)\n",
        "\n",
        "    return {\"feats\": feats_rst, \"joints\": joints_rst, \"length\": lengths, \"texts\": gen_output.get('cleaned_text', texts)}\n",
        "\n",
        "# Replace forward method\n",
        "model.forward = patched_forward.__get__(model, type(model))\n",
        "print(\"‚úì Model forward method patched to handle motion padding\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_U0TU2yfabE"
      },
      "source": [
        "## Step 3: Create API Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvppg99EfabF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import trimesh\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "def feats_to_smplx_dict(features, mean_tensor, std_tensor):\n",
        "    \"\"\"Convert 133-dim features to SMPL-X parameters dictionary\"\"\"\n",
        "    features = features * std_tensor + mean_tensor\n",
        "    T = features.shape[0]\n",
        "    zero_pose = torch.zeros(T, 36).to(features)\n",
        "    features_full = torch.cat([zero_pose, features], dim=-1)  # (T, 169)\n",
        "\n",
        "    # Extract SMPL-X parameters as dictionary\n",
        "    smplx_params = {\n",
        "        'root_pose': features_full[:, 0:3].cpu().numpy().tolist(),\n",
        "        'body_pose': features_full[:, 3:66].cpu().numpy().tolist(),\n",
        "        'lhand_pose': features_full[:, 66:111].cpu().numpy().tolist(),\n",
        "        'rhand_pose': features_full[:, 111:156].cpu().numpy().tolist(),\n",
        "        'jaw_pose': features_full[:, 156:159].cpu().numpy().tolist(),\n",
        "        'expression': features_full[:, 159:169].cpu().numpy().tolist(),\n",
        "    }\n",
        "    return smplx_params\n",
        "\n",
        "def smplx_params_to_glb_frames(smplx_params_dict, num_frames):\n",
        "    \"\"\"Convert SMPL-X parameters to GLB frames (base64 encoded)\"\"\"\n",
        "    # Create shape parameter\n",
        "    shape_param = torch.tensor([[-0.07284723, 0.1795129, -0.27608207, 0.135155, 0.10748172,\n",
        "                                 0.16037364, -0.01616933, -0.03450319, 0.01369138, 0.01108842]],\n",
        "                               device=mean.device, dtype=torch.float32)\n",
        "\n",
        "    glb_frames = []\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        # Convert lists back to tensors\n",
        "        root_pose = torch.tensor([smplx_params_dict['root_pose'][i]], dtype=torch.float32, device=mean.device)\n",
        "        body_pose = torch.tensor([smplx_params_dict['body_pose'][i]], dtype=torch.float32, device=mean.device)\n",
        "        lhand_pose = torch.tensor([smplx_params_dict['lhand_pose'][i]], dtype=torch.float32, device=mean.device)\n",
        "        rhand_pose = torch.tensor([smplx_params_dict['rhand_pose'][i]], dtype=torch.float32, device=mean.device)\n",
        "        jaw_pose = torch.tensor([smplx_params_dict['jaw_pose'][i]], dtype=torch.float32, device=mean.device)\n",
        "        expression = torch.tensor([smplx_params_dict['expression'][i]], dtype=torch.float32, device=mean.device)\n",
        "\n",
        "        # Generate mesh\n",
        "        with torch.no_grad():\n",
        "            vertices, _ = get_coord(\n",
        "                root_pose=root_pose,\n",
        "                body_pose=body_pose,\n",
        "                lhand_pose=lhand_pose,\n",
        "                rhand_pose=rhand_pose,\n",
        "                jaw_pose=jaw_pose,\n",
        "                shape=shape_param,\n",
        "                expr=expression\n",
        "            )\n",
        "\n",
        "        # Create trimesh with WHITE color\n",
        "        mesh = trimesh.Trimesh(\n",
        "            vertices=vertices[0].cpu().numpy(),\n",
        "            faces=smpl_x.face,\n",
        "            process=False\n",
        "        )\n",
        "        mesh.visual.vertex_colors = np.array([[255, 255, 255, 255]] * len(mesh.vertices))\n",
        "\n",
        "        # Export to GLB and encode to base64\n",
        "        glb_buffer = BytesIO()\n",
        "        mesh.export(file_obj=glb_buffer, file_type='glb')\n",
        "        glb_data = base64.b64encode(glb_buffer.getvalue()).decode('utf-8')\n",
        "        glb_frames.append(glb_data)\n",
        "\n",
        "    return glb_frames\n",
        "\n",
        "def generate_smplx_params(text, lang_token):\n",
        "    \"\"\"Generate SMPL-X parameters from text and language token\"\"\"\n",
        "    if not text.strip():\n",
        "        return None, \"‚ö†Ô∏è Please enter some text\"\n",
        "\n",
        "    try:\n",
        "        batch = {'text': [text], 'length': [0], 'src': [lang_token]}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.forward(batch, task=\"t2m\")\n",
        "\n",
        "        feats = output['feats'][0] if 'feats' in output else None\n",
        "\n",
        "        if feats is None:\n",
        "            return None, \"‚ùå Generation failed - no features produced\"\n",
        "\n",
        "        smplx_params = feats_to_smplx_dict(feats, mean, std)\n",
        "\n",
        "        return smplx_params, None\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "print(\"‚úì API functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18IBgDOQfabG"
      },
      "source": [
        "## Step 4: Create Flask API Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5twRir2ifabG"
      },
      "outputs": [],
      "source": [
        "# Create Flask API\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from threading import Thread\n",
        "import socket\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Enable CORS for frontend access\n",
        "\n",
        "@app.route('/api/generate', methods=['POST'])\n",
        "def api_generate():\n",
        "    \"\"\"API endpoint that takes lang_token and text, returns GLB frames\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        text = data.get('text', '').strip()\n",
        "        lang_token = data.get('lang_token', 'how2sign')\n",
        "\n",
        "        if not text:\n",
        "            return jsonify({'error': 'Text is required'}), 400\n",
        "\n",
        "        # Generate SMPL-X parameters\n",
        "        smplx_params, error = generate_smplx_params(text, lang_token)\n",
        "\n",
        "        if error:\n",
        "            return jsonify({'error': error}), 500\n",
        "\n",
        "        num_frames = len(smplx_params['body_pose'])\n",
        "\n",
        "        # Convert to GLB frames\n",
        "        glb_frames = smplx_params_to_glb_frames(smplx_params, num_frames)\n",
        "\n",
        "        # Return GLB frames (base64 encoded)\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'glb_frames': glb_frames,\n",
        "            'num_frames': num_frames,\n",
        "            'text': text,\n",
        "            'lang_token': lang_token\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/api/health', methods=['GET'])\n",
        "def health():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return jsonify({'status': 'ok', 'message': 'API is running'})\n",
        "\n",
        "def get_free_port():\n",
        "    \"\"\"Get a free port\"\"\"\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind(('', 0))\n",
        "        s.listen(1)\n",
        "        port = s.getsockname()[1]\n",
        "    return port\n",
        "\n",
        "port = get_free_port()\n",
        "\n",
        "def run_flask():\n",
        "    app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)\n",
        "\n",
        "flask_thread = Thread(target=run_flask, daemon=True)\n",
        "flask_thread.start()\n",
        "\n",
        "# Wait a moment for Flask to start\n",
        "time.sleep(2)\n",
        "\n",
        "print(f\"\\n‚úÖ Flask API started!\")\n",
        "print(f\"üì° API URL: http://localhost:{port}/api/generate\")\n",
        "print(f\"üíö Health check: http://localhost:{port}/api/health\")\n",
        "print(f\"\\nüìù API Usage:\")\n",
        "print(f\"  POST /api/generate\")\n",
        "print(f\"  Body: {{'text': 'Hello world', 'lang_token': 'how2sign'}}\")\n",
        "print(f\"  Response: {{'success': True, 'glb_frames': [...], 'num_frames': N}}\")\n",
        "print(f\"\\n‚ö†Ô∏è  To expose this API publicly, use ngrok:\")\n",
        "print(f\"  !pip install pyngrok\")\n",
        "print(f\"  from pyngrok import ngrok\")\n",
        "print(f\"  public_url = ngrok.connect({port})\")\n",
        "print(f\"  print(f'Public URL: {{public_url}}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1fojggOfabH"
      },
      "source": [
        "## Step 5: Expose API Publicly (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkKP_r4yfabH"
      },
      "outputs": [],
      "source": [
        "# Expose API using ngrok (for frontend access)\n",
        "!pip install -q pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "# Setup ngrok authentication\n",
        "print(\"\\nüîê ngrok Authentication Setup\")\n",
        "print(\"=\" * 60)\n",
        "print(\"To use ngrok, you need an authtoken.\")\n",
        "print(\"1. Sign up at: https://dashboard.ngrok.com/signup\")\n",
        "print(\"2. Get your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Option 1: Use environment variable (if set)\n",
        "ngrok_token = os.environ.get('NGROK_AUTHTOKEN', None)\n",
        "\n",
        "# Option 2: Prompt user to enter token\n",
        "if not ngrok_token:\n",
        "    print(\"\\nEnter your ngrok authtoken (or press Enter to skip):\")\n",
        "    user_token = getpass.getpass(\"ngrok authtoken: \").strip()\n",
        "    if user_token:\n",
        "        ngrok_token = user_token\n",
        "        os.environ['NGROK_AUTHTOKEN'] = ngrok_token\n",
        "\n",
        "if ngrok_token:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    print(\"\\n‚úì ngrok authtoken configured\")\n",
        "\n",
        "    # Create public tunnel\n",
        "    try:\n",
        "        public_url = ngrok.connect(port)\n",
        "        print(f\"\\nüåê Public API URL: {public_url}\")\n",
        "        print(f\"\\nüìã Update your frontend with this URL:\")\n",
        "        print(f\"   const API_URL = '{public_url}/api/generate';\")\n",
        "        print(f\"\\n‚ö†Ô∏è  This URL will expire when the Colab session ends!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error creating ngrok tunnel: {e}\")\n",
        "        print(\"\\nYou can still use the API locally at:\")\n",
        "        print(f\"   http://localhost:{port}/api/generate\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No ngrok authtoken provided. Skipping public tunnel.\")\n",
        "    print(\"\\nYou can still use the API locally at:\")\n",
        "    print(f\"   http://localhost:{port}/api/generate\")\n",
        "    print(\"\\nTo expose publicly, run this cell again with your authtoken.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgIOATjghys1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}